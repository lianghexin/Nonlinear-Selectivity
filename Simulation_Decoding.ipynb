{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0651960d",
   "metadata": {},
   "source": [
    "The purpose of this code is to investigate how nonlinear choice selectivity (switch signal) contributes to the population encoding of choice history, which is fundamental for flexible decision-making. We first generated surrogate neural datasets that have different population encoding properties of linear and nonlinear choice selectivty, and then decode the choice history across two successive trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef5e1686",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mat4py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.io as sio\n",
    "import math\n",
    "import warnings\n",
    "import warnings\n",
    "import time\n",
    "from itertools import combinations\n",
    "from itertools import product\n",
    "\n",
    "from numpy import linalg as LA\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import nbinom\n",
    "from scipy import stats\n",
    "from scipy import optimize\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import linear_model\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "from mpl_toolkits import mplot3d\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0121576c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load preprocessed behavioral + neural data (matlab file)\n",
    "\n",
    "# probablistic reversal learning task\n",
    "data = mat4py.loadmat('C:/Users/liang/Documents/GitHub/ChoiceInteraction/PRL_all_-500_500_250_1500_spkcounts_norm0.mat')\n",
    "PRL = pd.DataFrame.from_dict(data['Data'])\n",
    "Var = data['Var']\n",
    "varName = { i : Var[i] for i in range(len(Var)) }\n",
    "PRL.rename(columns=varName,inplace=True)\n",
    "PRL.dropna(inplace=True)\n",
    "ts = PRL.shape[1] - len(Var)\n",
    "PRL_regressors = ['Loc','PreLoc','RL','PRL','LocInter','Col','PreCol','RC','PRC','ColInter',\n",
    "    'Rwd','PreRwd','POS','ChosenMag','UnchosenMag','LMag','HVL','SwitchHVL']\n",
    "\n",
    "# matching pennies task\n",
    "data = mat4py.loadmat('C:/Users/liang/Documents/GitHub/ChoiceInteraction/MP_all_-500_500_250_1500_spkcounts_norm0.mat')\n",
    "MP = pd.DataFrame.from_dict(data['Data'])\n",
    "Var = data['Var']\n",
    "varName = { i : Var[i] for i in range(len(Var)) }\n",
    "MP.rename(columns=varName,inplace=True)\n",
    "MP.dropna(inplace=True)\n",
    "MP_regressors = ['Loc','PreLoc','RL','PRL','LocInter','Rwd','PreRwd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3c3e88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_coef(data, regressors, timestamps):\n",
    "\n",
    "    \"\"\"\n",
    "    Apply multiple linear regression model to the spike counts data to examine how single neurons were modulated \n",
    "    by the main task variables and the high-level interaction terms among these task variables. \n",
    "    \n",
    "    Args:\n",
    "        data: pandas dataframe, has all the behavioral and neural data from a task;\n",
    "              each row includes the spike counts of one neuron throughout different epochs within one trial,\n",
    "              and the corresponding behavioral variables, and recording details from that trial.\n",
    "        regressors: independent variables for the regression model\n",
    "        timestamps: the specific epochs to analyze\n",
    "        \n",
    "    Returns:\n",
    "        coef: regression coefficients for [each neuron, each regressor, each epoch]\n",
    "        res: residual sum of errors for [each neuron, each epoch]\n",
    "                \n",
    "    \"\"\"\n",
    "    \n",
    "    cell_num = data.cellid.unique().size   \n",
    "    coef = np.zeros((cell_num,len(regressors)+1,len(timestamps)))\n",
    "    residual = np.zeros((cell_num,len(timestamps)))\n",
    "    \n",
    "    clf = linear_model.LinearRegression()\n",
    "\n",
    "    for c in range(1,cell_num+1):\n",
    "\n",
    "        cData = data[(data['cellid']==c)] \n",
    "        F = cData.loc[:,regressors].to_numpy()\n",
    "        \n",
    "        for time_ind, t in enumerate(timestamps):\n",
    "        \n",
    "            FR = cData[cData.columns[-ts:]].to_numpy()[:,t]\n",
    "\n",
    "            # first gaussianize the data, and then apply the regression model\n",
    "            FR_sorted = np.sort(FR)\n",
    "            ind = np.argsort(FR)\n",
    "            FR_g = np.random.normal(size=len(FR_sorted))\n",
    "            FR_g_sorted = np.sort(FR_g)\n",
    "            FR_t = np.zeros(len(FR_sorted))\n",
    "            FR_t[ind] = FR_g_sorted\n",
    "\n",
    "            clf.fit(F, FR_t)\n",
    "            coef[c-1,:,time_ind] = np.append(clf.intercept_,clf.coef_)\n",
    "            residual[c-1,time_ind] = np.var(FR_t-np.dot(F,coef[c-1,1:,time_ind])-coef[c-1,0,time_ind])\n",
    "                \n",
    "    original = {'coef': coef, \n",
    "                'res': residual} \n",
    "                \n",
    "    return original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd5f8788",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coef_manipulation(original_coef, regressors, var, coefmode, corr, timestamps): \n",
    "\n",
    "    \"\"\"\n",
    "    Manipulate the regression coefficients for the nonlinear choice selectivity (switch) obtained from the linear regression model,\n",
    "    and then generate surrogate neural activity with designed population encoding properties of choice-related signals.\n",
    "    There are two types of manipulations (coefmode):\n",
    "    1) 'Removal', removal/lesion of the switch signal. \n",
    "    2) 'Correlated', shuffle the regression coefficients of switch across neural population, so that the population activity patterns \n",
    "       evoked by switch and choice are correlated, and takes the targeted value (corr). \n",
    "    \n",
    "    Args:\n",
    "        original_coef: regression coefficients obtained from function 'calculate_coef'\n",
    "        regressors: independent variables for the regression model\n",
    "        var: choice variable, 'Col' for target color or 'Loc' for target location\n",
    "        coefmode: 'Removal' or 'Correlated'\n",
    "        corr: [-1,1], targeted correlation coefficient if coefmode=='Correlated'\n",
    "        timestamps: the specific epochs to analyze\n",
    "        \n",
    "    Returns:\n",
    "        mani_coef: regression coefficients for [each neuron, each regressor, each epoch] after manipulation\n",
    "                \n",
    "    \"\"\"\n",
    "    \n",
    "    cell_num = original_coef.shape[0] \n",
    "    timestamps = original_coef.shape[2] \n",
    "    mani_coef = original_coef.copy()\n",
    "    varOI = [var,'Pre'+var,var+'Inter']\n",
    "    var1_ind = np.where([x==var for x in regressors])[0][0]+1\n",
    "    var2_ind = np.where([x==var+'Inter' for x in regressors])[0][0]+1\n",
    "    \n",
    "    if coefmode == 'Correlated':\n",
    "                    \n",
    "        a = np.random.multivariate_normal([0,0],[[1,corr],[corr,1]],size=cell_num)\n",
    "        a_sorted = np.zeros((cell_num,2))\n",
    "        var2_reordered = np.zeros(cell_num)\n",
    "\n",
    "        for time_ind in range(timestamps):\n",
    "            \n",
    "            var1_coef = original_coef[:,var1_ind,time_ind]\n",
    "            var2_coef = original_coef[:,var2_ind,time_ind]\n",
    "\n",
    "            ind = np.argsort(var1_coef)  \n",
    "            a_sorted[ind,:] = a[a[:,0].argsort()]\n",
    "\n",
    "            var2_cellind = np.argsort(a_sorted[:,1])\n",
    "            var2_sorted = np.sort(var2_coef) \n",
    "\n",
    "            mani_coef[var2_cellind,var2_ind,time_ind] = var2_sorted\n",
    "                \n",
    "    if coefmode == 'Removal':\n",
    "        mani_coef[:,var2_ind,:] = 0\n",
    "            \n",
    "    return mani_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "217d215e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(data, regressors, var, res, mani_coef, timestamps):\n",
    "    \n",
    "    \"\"\"\n",
    "    Generate surrogate data using the manipulated regression coefficients.\n",
    "    \n",
    "    Args:\n",
    "        var: choice variable, 'Col' for target color or 'Loc' for target location\n",
    "        res: residual sum of errors from function 'calculate_coef'\n",
    "        mani_coef: manipulated regression coefficients\n",
    "        \n",
    "    Returns:\n",
    "        surrogateData: simulated neural activity\n",
    "        refit_coef:  apply the same regression model again to the surrogate data to examine if the manipulation is valid\n",
    "                \n",
    "    \"\"\"\n",
    "    \n",
    "    cell_num = data.cellid.unique().size \n",
    "    surrogateData = data.copy()\n",
    "    Y = np.array([])\n",
    "    varOI = [var,'Pre'+var,var+'Inter']\n",
    "    refit_coef = np.zeros(mani_coef.shape)\n",
    "    clf = linear_model.LinearRegression()  \n",
    "        \n",
    "    for c in range(1,cell_num+1):\n",
    "\n",
    "        cData = data[(data['cellid']==c)] \n",
    "        F = cData.loc[:,regressors].to_numpy()\n",
    "        y = np.zeros((len(F),len(timestamps)))\n",
    "        \n",
    "        for time_ind, t in enumerate(timestamps):\n",
    "        \n",
    "            FR = cData[cData.columns[-ts:]].to_numpy()[:,t]\n",
    "            y_gaussian = mani_coef[c-1,0,time_ind] + np.dot(F,mani_coef[c-1,1:,time_ind]) + np.random.normal(0, np.sqrt(res[c-1,time_ind]), len(FR))\n",
    "            FR_sorted = np.sort(FR)      # sort the original spike counts\n",
    "            ind = np.argsort(y_gaussian)  # map \n",
    "            y[ind,time_ind] = FR_sorted\n",
    "\n",
    "            clf.fit(F, y[:,time_ind])\n",
    "            refit_coef[c-1,:,time_ind] = np.append(clf.intercept_,clf.coef_)\n",
    "        \n",
    "        if len(Y) == 0:\n",
    "            Y = y\n",
    "        else:\n",
    "            Y = np.append(Y,y,axis=0)\n",
    "            \n",
    "    surrogateData.iloc[:,-ts+np.array(timestamps)] = Y\n",
    "        \n",
    "    return surrogateData, refit_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d9bd6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(data, var, train_trialNum=100, test_trialNum=50):\n",
    "    \n",
    "    \"\"\"\n",
    "    Generate psuedo-trials. Because most of the neurons were collected from separate sessions, here we resample the neural\n",
    "    activity from individual neurons under the same behavioral condition and construct a population activity for one trial\n",
    "    as if these neurons were recorded simultaneously. \n",
    "    \n",
    "    Args:\n",
    "        var: choice variable, 'Col' for target color or 'Loc' for target location\n",
    "        res: residual sum of errors from function 'calculate_coef'\n",
    "        mani_coef: manipulated regression coefficients\n",
    "        \n",
    "    Returns:\n",
    "       training set and testing set\n",
    "    \"\"\"\n",
    "    \n",
    "    cell_num = data.cellid.unique()\n",
    "    k = 3\n",
    "    train = [[] for x in range(k)]\n",
    "    test = [[] for x in range(k)]\n",
    "\n",
    "    for val1 in np.unique(data[var]):  \n",
    "        for val2 in np.unique(data['Pre'+var]):\n",
    "            for val3 in np.unique(data['PreRwd']):\n",
    "\n",
    "                temp = data[(data[var]==val1) & (data['Pre'+var]==val2) & (data['PreRwd']==val3)]\n",
    "                train_temp = [np.zeros([train_trialNum,ts,cell_num.size]) for x in range(k)]\n",
    "                test_temp = [np.zeros([test_trialNum,ts,cell_num.size]) for x in range(k)]\n",
    "\n",
    "                for c in range(cell_num.size):\n",
    "                    \n",
    "                    cData = temp[temp.cellid==cell_num[c]]\n",
    "\n",
    "                    trialNum = np.array(cData.index)\n",
    "                    kf = KFold(n_splits=k, shuffle=True)\n",
    "\n",
    "                    if len(trialNum)<3:\n",
    "\n",
    "                        for i in range(k):\n",
    "                            train_temp[i][:,:,c] = np.nan\n",
    "                            test_temp[i][:,:,c] = np.nan\n",
    "\n",
    "                    else:\n",
    "\n",
    "                        for i, (c_train_ind, c_test_ind) in enumerate(kf.split(trialNum)):\n",
    "\n",
    "                            c_train = cData.iloc[c_train_ind]\n",
    "                            c_test = cData.iloc[c_test_ind]        \n",
    "                            c_train_rsm = np.random.randint(c_train.shape[0],size=train_trialNum)\n",
    "                            c_test_rsm = np.random.randint(c_test.shape[0],size=test_trialNum)\n",
    "                            c_train_data = c_train.iloc[c_train_rsm]\n",
    "                            c_test_data = c_test.iloc[c_test_rsm]\n",
    "\n",
    "                            train_temp[i][:,:,c] = c_train_data[c_train_data.columns[-ts:]].to_numpy()\n",
    "                            test_temp[i][:,:,c] = c_test_data[c_test_data.columns[-ts:]].to_numpy()\n",
    "\n",
    "                for i in range(k):\n",
    "\n",
    "                    train_temp[i]  = np.concatenate((train_temp[i],np.tile([val1,val2,val1*val2],(train_trialNum,ts,1))), axis=2)\n",
    "                    test_temp[i]  = np.concatenate((test_temp[i],np.tile([val1,val2,val1*val2],(test_trialNum,ts,1))), axis=2)                    \n",
    "\n",
    "                    if len(train[i]) == 0:\n",
    "                        train[i] = train_temp[i]\n",
    "                        test[i] = test_temp[i]\n",
    "                    else:\n",
    "                        train[i] = np.append(train[i],train_temp[i],axis=0) \n",
    "                        test[i] = np.append(test[i],test_temp[i],axis=0) \n",
    "\n",
    "\n",
    "    return train, test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebdf35f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(data, var, timestamps, num_iter=10, train_trialNum=100, test_trialNum=50):\n",
    "    \n",
    "    \"\"\"\n",
    "    Apply linear support vector machine in combination with k-fold cross validation to decode the agent's \n",
    "    current choice, previous choice, switch and choice history across two successive trials. \n",
    "    \n",
    "    Args:\n",
    "        same as above \n",
    "        \n",
    "    Returns:\n",
    "        Accuracy: decoding/classification accuracy for these 4 variables\n",
    "        Projection: the projection onto the encoding axis of each variable defined by SVM, one data point is one pseudo-trial\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    Accuracy = np.zeros((num_iter,3,len(timestamps),5))\n",
    "    Projection = np.zeros((num_iter,3,len(timestamps),test_trialNum*8,7))\n",
    "    \n",
    "    clf1 = SVC(kernel='linear')\n",
    "    clf2 = SVC(kernel='linear')\n",
    "    clf3 = SVC(kernel='linear')\n",
    "    clf4 = SVC(kernel='linear',probability=True) \n",
    "        \n",
    "    for n in range(num_iter):\n",
    "\n",
    "        train,test = create_dataset(data,var,'Pre'+var, train_trialNum=100, test_trialNum=50)\n",
    "\n",
    "        for k in range(3):\n",
    "\n",
    "            cellindex = (~np.isnan(train[k][:,0,:-3].mean(axis=0))) & (~np.isnan(test[k][:,0,:-3].mean(axis=0)))  \n",
    "            \n",
    "            for i, t in enumerate(timestamps):\n",
    "\n",
    "                clf1.fit(train[k][:,t,:-3][:,cellindex],train[k][:,t,-3])\n",
    "                clf2.fit(train[k][:,t,:-3][:,cellindex],train[k][:,t,-2])\n",
    "                clf3.fit(train[k][:,t,:-3][:,cellindex],train[k][:,t,-1])\n",
    "                clf4.fit(train[k][:,t,:-3][:,cellindex],train[k][:,t,-3]*2+train[k][:,t,-2])\n",
    "\n",
    "                Accuracy[n,k,i,0] = accuracy_score(clf1.predict(test[k][:,t,:-3]),test[k][:,t,-3])\n",
    "                Accuracy[n,k,i,1] = accuracy_score(clf2.predict(test[k][:,t,:-3]),test[k][:,t,-2])\n",
    "                Accuracy[n,k,i,2] = accuracy_score(clf3.predict(test[k][:,t,:-3]),test[k][:,t,-1])\n",
    "                Accuracy[n,k,i,3] = accuracy_score(clf4.predict(test[k][:,t,:-3]),test[k][:,t,-3]*2+test[k][:,t,-2])\n",
    "                Accuracy[n,k,i,4] = t\n",
    "                \n",
    "                Projection[n,k,i,:,0] = test[k][:,t,-3]\n",
    "                Projection[n,k,i,:,1] = test[k][:,t,-2]\n",
    "                Projection[n,k,i,:,2] = test[k][:,t,-1]\n",
    "                Projection[n,k,i,:,3] = np.ravel((np.dot(test[k][:,t,:-3][:,cellindex],np.transpose(clf1.coef_))+clf1.intercept_)/LA.norm(clf1.coef_))\n",
    "                Projection[n,k,i,:,4] = np.ravel((np.dot(test[k][:,t,:-3][:,cellindex],np.transpose(clf2.coef_))+clf2.intercept_)/LA.norm(clf2.coef_))\n",
    "                Projection[n,k,i,:,5] = np.ravel((np.dot(test[k][:,t,:-3][:,cellindex],np.transpose(clf3.coef_))+clf3.intercept_)/LA.norm(clf3.coef_))\n",
    "                Projection[n,k,i,:,6] = t\n",
    "                \n",
    "                \n",
    "    Accuracy_df = pd.DataFrame(data=Accuracy.reshape(-1,5),columns=['Current','Previous','Switch','Choice Sequence','Time'])\n",
    "    Projection_df = pd.DataFrame(data=Projection.reshape(-1,7),columns=['Current','Previous','Switch','CurrentProjection',\n",
    "                                                                        'PreviousProjection','SwitchProjection','Time'])\n",
    "        \n",
    "    return Accuracy_df, Projection_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "id": "bee61225",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_reorder(corrcoef,accuracy,Allcoef,var,regressors,title,filename):\n",
    "    \n",
    "    \"\"\"\n",
    "    Scatter plot the relationship between correlation coefficient and the decoding accuracy. \n",
    "    \n",
    "    \"\"\"    \n",
    "    \n",
    "    varOI = [var,'Pre'+var,var+'Inter']\n",
    "    var_ind = np.zeros(3)\n",
    "    for ii in range(3):\n",
    "        var_ind[ii] = np.where([x==varOI[ii] for x in regressors])[0][0]+1\n",
    "    var_coef = Allcoef[:,:,var_ind.astype(int)]\n",
    "    coef_norm = np.linalg.norm(var_coef, axis=1)\n",
    "    regmat = np.concatenate([corrcoef,coef_norm],axis=1)\n",
    "    \n",
    "    plt.close('all')\n",
    "    my_dpi = 120\n",
    "    fig = plt.figure(figsize=(2000/my_dpi, 500/my_dpi), dpi=my_dpi,facecolor=(1, 1, 1))\n",
    "    gs = gridspec.GridSpec(1,4)\n",
    "    titles=['Choice(t)','Choice(t-1)','Switch','Choice sequence']\n",
    "\n",
    "    for c in range(4):\n",
    "        \n",
    "        ax = plt.subplot(gs[c])   \n",
    "        mdl=sm.OLS(accuracy[:-3,c],np.abs(regmat[:-3]))\n",
    "        res = mdl.fit() \n",
    "        ax.scatter(corrcoef[:-3],accuracy[:-3,c],color=[0.8,0.8,0.8])\n",
    "\n",
    "        if res.pvalues[0]<0.01:\n",
    "            ax.text(-0.7,0.45,'w='+f\"{res.params[0]:.3f}\"+'\\np='+f\"{res.pvalues[0]:.1e}\",fontsize=14)\n",
    "        else:\n",
    "            ax.text(-0.7,0.45,'w='+f\"{res.params[0]:.3f}\"+'\\np='+f\"{res.pvalues[0]:.2f}\",fontsize=14)\n",
    "        ax.set_ylim(0.4,1.1)\n",
    "        ax.set_xlim(-0.8,0.8)\n",
    "\n",
    "        if c==0:\n",
    "            ax.set_ylabel('Accuracy (%)', fontsize=14)\n",
    "\n",
    "        ax.set_title(titles[c],fontsize=14)\n",
    "        ax.set_position([c*0.9/4+0.05,0.15,0.19,0.7])\n",
    "        ax.set_xticks([-0.5,0,0.5])\n",
    "        ax.set_xticklabels([-0.5,0,0.5], fontsize=14)\n",
    "        ax.set_yticks(np.linspace(0.4,1,4))\n",
    "        ax.set_yticklabels(np.linspace(0.4,1,4), fontsize=14)\n",
    "        \n",
    "    fig.text(0.5, 0.03, 'Correlation between Choice(t) and Switch', ha='center', fontsize=14)\n",
    "    \n",
    "    plt.suptitle(title,fontsize=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3dc8af50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def original_removal_cmp(data, regressors, var):\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    Compare the decoding accuracy and projection between simulated data using the un-manipulated/original regression coefficients\n",
    "    and the regression coefficients after the removal of switch signal. \n",
    "    \n",
    "    \"\"\"    \n",
    "\n",
    "    original = calculate_coef(data, regressors, np.arange(18))\n",
    "    mani_coef = coef_manipulation(original['coef'], regressors, var, 'Removal', 0, np.arange(18))\n",
    "    \n",
    "    original_data, original_refit_coef = generate_data(data, regressors, var, original, original['coef'], np.arange(18))\n",
    "    removal_data, removal_refit_coef = generate_data(data, regressors, var, original, mani_coef, np.arange(18))\n",
    "    \n",
    "    original_accuracy, original_projection = decode(original_data, var, np.arange(18), num_iter=2)\n",
    "    removal_accuracy, removal_projection = decode(removal_data, var, np.arange(18), num_iter=2)\n",
    "    \n",
    "    return original_accuracy, original_projection, removal_accuracy, removal_projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "c5dc1ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorder_data(data, regressors, var):\n",
    "    \n",
    "    \"\"\"\n",
    "    Get the decoding accuracy and projection for the datasets, in which the population encoding of switch and choice \n",
    "    are correlated. \n",
    "    \n",
    "    \"\"\"    \n",
    "    \n",
    "    original = calculate_coef(data, regressors, [6])\n",
    "    mani_coef = coef_manipulation(original['coef'], regressors, var, 'Reorder', 1, [6])\n",
    "    reorder_data, reorder_refit_coef = generate_data(data, regressors, var, original, mani_coef, [6])\n",
    "    reorder_accuracy, reorder_projection = decode(reorder_data, var, [6], num_iter=2)\n",
    "    \n",
    "    return reorder_accuracy, reorder_projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "id": "5fc3f5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_original_removal(original_accuracy,removal_accuracy,task):\n",
    "\n",
    "    \"\"\"\n",
    "    Plot the decoding accuracy for the datasets with original regression coefficients versus the one with switch signal removed\n",
    "    \n",
    "    \"\"\"  \n",
    "    \n",
    "    plt.close('all')\n",
    "    fig, axs = plt.subplots(2, 4, figsize=(6,4),facecolor=(1, 1, 1))\n",
    "    variables = ['Current','Previous','Switch','Choice Sequence']\n",
    "\n",
    "    if task == 'PRL':\n",
    "        ticklabels = ['0', '0.5', '1']\n",
    "        ticks=[[2,4,6],[11,13,15]]\n",
    "        tlim=[[-1,8],[8,17]]\n",
    "    else:\n",
    "        ticklabels = ['0', '0.5']\n",
    "        ticks=[[2,4],[11,13]]\n",
    "        tlim=[[0,7],[9,16]]\n",
    "        \n",
    "    ticksize=10\n",
    "    titlesize=12\n",
    "\n",
    "    for var in range(4):\n",
    "        \n",
    "        for ax_ind in range(2):\n",
    "            \n",
    "#             ax=plt.subplot(gs[int(np.floor(var/2)),ax_ind+2*(var%2)])\n",
    "            ax=axs[int(np.floor(var/2)),ax_ind+2*(var%2)]\n",
    "            sns.lineplot(original_accuracy[(original_accuracy.Time>tlim[ax_ind][0]) & (original_accuracy.Time<tlim[ax_ind][1])],\n",
    "                         x='Time',y=variables[var],color='forestgreen',ax=ax,zorder=2,marker='o',markeredgecolor=None)\n",
    "            sns.lineplot(removal_accuracy[(removal_accuracy.Time>tlim[ax_ind][0]) & (removal_accuracy.Time<tlim[ax_ind][1])],\n",
    "                         x='Time',y=variables[var],color='darkviolet',ax=ax,zorder=2,marker='o',markeredgecolor=None)\n",
    "\n",
    "            ax.set_xticks(ticks[ax_ind])\n",
    "            ax.set_ylim(0,1.05)\n",
    "            ax.set_xlim(tlim[ax_ind][0]+1,tlim[ax_ind][1]-1)\n",
    "                \n",
    "                \n",
    "            if ax_ind == 0:\n",
    "\n",
    "                ax.fill_between([2,4],[1,1],color=[0.6,0.6,0.6],alpha=0.15,edgecolor=None)\n",
    "                ax.spines[['right', 'top']].set_visible(False)\n",
    "                ax.set_xlabel('Target onset',fontsize=ticksize)\n",
    "                    \n",
    "                if var%2==0:\n",
    "                    ax.set_ylabel('Accuracy (%)')\n",
    "                else:\n",
    "                    ax.set_ylabel('')\n",
    "                    ax.set_yticklabels('')\n",
    "                \n",
    "            else:\n",
    "                ax.fill_between([11,13],[1,1],color=[0.6,0.6,0.6],alpha=0.15,edgecolor=None)\n",
    "                ax.spines[['left', 'right', 'top']].set_visible(False)\n",
    "                ax.set_xlabel('Feedback onset',fontsize=ticksize)\n",
    "                ax.set_ylabel('')\n",
    "                ax.set_yticks([])\n",
    "                \n",
    "            if var == 3:\n",
    "                ax.plot(np.array(tlim[ax_ind]),[0.25,0.25],'k--',zorder=1)\n",
    "            else:\n",
    "                ax.plot(np.array(tlim[ax_ind]),[0.5,0.5],'k--',zorder=1)     \n",
    "                \n",
    "            if var < 2:\n",
    "                ax.set_xticklabels('')\n",
    "                ax.set_xlabel('')\n",
    "            else:\n",
    "                ax.set_xticklabels(ticklabels,fontsize=ticksize)\n",
    "                    \n",
    "\n",
    "                \n",
    "            ax.set_position([0.2+0.4*(var%2)+0.17*ax_ind,0.55-0.4*np.floor(var/2),0.15,0.3])\n",
    "\n",
    "                    \n",
    "        ax.text(10,1.05,variables[var],fontsize=titlesize,ha='center')\n",
    "\n",
    "\n",
    "    plt.suptitle(task,fontsize=titlesize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "b66d178e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotProjection(Projection,task,var):\n",
    "    \n",
    "    \"\"\"\n",
    "    Plot the projection of population activity onto the encoding axis of each task variable, which to some extent serves as\n",
    "    dimensionality reduction. Each datapoint represents a pseudo-trial. \n",
    "    \n",
    "    \"\"\"  \n",
    "    \n",
    "    plt.close('all')\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(projection='3d')   \n",
    "    colors = ['#59ce8f', '#ff7f50', '#0761f2', '#7a0bc0']\n",
    "\n",
    "    for var1 in [-1,1]:\n",
    "        for var2 in [-1,1]:\n",
    "            \n",
    "            c = int(var1+var2/2+1.5)\n",
    "            \n",
    "            conditioned = Projection[(Projection.Current==var1) & (Projection.Previous==var2)]\n",
    "            conditioned_mean = conditioned.mean()\n",
    "\n",
    "            ax.scatter3D(conditioned.CurrentProjection.values, conditioned.PreviousProjection.values,\n",
    "                         conditioned.SwitchProjection.values, color=colors[c], marker='o', depthshade=True, s=20, alpha=0.5)\n",
    "\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    ax.xaxis.pane.fill = False\n",
    "    ax.yaxis.pane.fill = False\n",
    "    ax.zaxis.pane.fill = False\n",
    "    \n",
    "    # Now set color to white (or whatever is \"invisible\")\n",
    "    ax.xaxis.pane.set_edgecolor('w')\n",
    "    ax.yaxis.pane.set_edgecolor('w')\n",
    "    ax.zaxis.pane.set_edgecolor('w')\n",
    "    ax.grid(False)\n",
    "    \n",
    "    if var=='Col':\n",
    "        \n",
    "        plt.legend(['G->G','R->G','G->R','R->R'])\n",
    "        \n",
    "        ax.set_xlim(-5,5)\n",
    "        ax.set_ylim(-5,5)\n",
    "        ax.set_zlim(-5,5)\n",
    "\n",
    "        ax.set_xticks([-2.5,0,2.5])\n",
    "        ax.set_yticks([-2.5,0,2.5])\n",
    "        ax.set_zticks([-2.5,0,2.5])\n",
    "        \n",
    "    else:\n",
    "        plt.legend(['L->L','R->L','L->R','R->R'])\n",
    "        \n",
    "        ax.set_xlim(-30,30)\n",
    "        ax.set_ylim(-10,10)\n",
    "        ax.set_zlim(-10,10)\n",
    "\n",
    "        ax.set_xticks([-15,0,15])\n",
    "        ax.set_yticks([-5,0,5])\n",
    "        ax.set_zticks([-5,0,5])\n",
    "\n",
    "    ax.set_xlabel(var+'(t)')\n",
    "    ax.set_ylabel(var+'(t-1)')\n",
    "    ax.set_zlabel('Switch')\n",
    "    ax.view_init(azim=100,elev=-170)\n",
    "    plt.savefig(task+' '+var+' projection on the encoding axis')\n",
    "\n",
    "    ax.view_init(azim=0,elev=0)\n",
    "    plt.savefig(task+' '+var+' projection on the encoding axis 1')\n",
    "\n",
    "    ax.view_init(azim=90,elev=0)\n",
    "    plt.savefig(task+' '+var+' projection on the encoding axis 2')\n",
    "\n",
    "    ax.view_init(azim=90,elev=90)\n",
    "    plt.savefig(task+' '+var+' projection on the encoding axis 3')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
